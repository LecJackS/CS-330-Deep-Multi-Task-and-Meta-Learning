{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load_data\n",
    "#from load_data import DataGenerator\n",
    "from load_data import get_images, image_file_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "class DataGenerator(object):\n",
    "    \"\"\"\n",
    "    Data Generator capable of generating batches of Omniglot data.\n",
    "    A \"class\" is considered a class of omniglot digits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, num_samples_per_class, config={}):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        config = {'sad':''}\n",
    "\n",
    "        data_folder = config.get('data_folder', './omniglot_resized')\n",
    "        self.img_size = config.get('img_size', (28, 28))\n",
    "\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "        \n",
    "       \n",
    "\n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                             for family in os.listdir(data_folder)\n",
    "                             if os.path.isdir(os.path.join(data_folder, family))\n",
    "                             for character in os.listdir(os.path.join(data_folder, family))\n",
    "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "\n",
    "        random.seed(1)\n",
    "        random.shuffle(character_folders)\n",
    "        num_val = 100\n",
    "        num_train = 1100\n",
    "        self.metatrain_character_folders = character_folders[: num_train]\n",
    "        self.metaval_character_folders = character_folders[\n",
    "            num_train:num_train + num_val]\n",
    "        self.metatest_character_folders = character_folders[\n",
    "            num_train + num_val:]\n",
    "\n",
    "    def sample_batch(self, batch_type, batch_size, K=1, N=5):\n",
    "        \"\"\"\n",
    "        Samples a batch for training, validation, or testing\n",
    "        Args:\n",
    "            batch_type: train/val/test\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "        elif batch_type == \"val\":\n",
    "            folders = self.metaval_character_folders\n",
    "        else:\n",
    "            folders = self.metatest_character_folders\n",
    "\n",
    "        #############################\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "        all_image_batches = np.array(batch_size, K, N, 784)\n",
    "        all_label_batches = np.array(batch_size, K, N, N)\n",
    "        for b in range(batch_size):\n",
    "            # Take N samples from all alphabet folders\n",
    "            sample_paths  = random.sample(folders, N)\n",
    "            sample_labels = [os.path.basename(os.path.split(family)[0]) for family in sample_paths]\n",
    "            images_labels = get_images(sample_paths, sample_labels, K)\n",
    "            \n",
    "            # TODO: COrrect use of dimension\n",
    "            all_image_batches = [i for i,l in images_labels]\n",
    "            all_label_batches = [l for i,l in images_labels]\n",
    "        #############################\n",
    "\n",
    "        return all_image_batches, all_label_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray((2,3,4,5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'data_folder':'./'}\n",
    "data = DataGenerator(5, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asd'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c={}\n",
    "c.get('data_folder', 'asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples per class: 1\n",
      "# classes: 5\n",
      "Image size: (28, 28)\n",
      "Input dimension: 784\n",
      "Output dimension: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"# samples per class:\", data.num_samples_per_class)\n",
    "print(\"# classes:\",  data.num_classes)\n",
    "print(\"Image size:\", data.img_size)\n",
    "print(\"Input dimension:\", data.dim_input)\n",
    "print(\"Output dimension:\",data.dim_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of meta train folders: 1100\n",
      "# of meta val folders:   100\n",
      "# of meta test folders:  423\n"
     ]
    }
   ],
   "source": [
    "print(\"# of meta train folders:\", len(data.metatrain_character_folders))\n",
    "print(\"# of meta val folders:  \", len(data.metaval_character_folders))\n",
    "print(\"# of meta test folders: \", len(data.metatest_character_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./omniglot_resized/Early_Aramaic/character05',\n",
       " './omniglot_resized/Malayalam/character40',\n",
       " './omniglot_resized/Ojibwe_(Canadian_Aboriginal_Syllabics)/character12',\n",
       " './omniglot_resized/Tifinagh/character09',\n",
       " './omniglot_resized/Kannada/character02',\n",
       " './omniglot_resized/Armenian/character34',\n",
       " './omniglot_resized/Gurmukhi/character18',\n",
       " './omniglot_resized/Kannada/character25',\n",
       " './omniglot_resized/Gurmukhi/character17',\n",
       " './omniglot_resized/Japanese_(katakana)/character31']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metatrain_character_folders[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./omniglot_resized/Braille/character12',\n",
       " './omniglot_resized/N_Ko/character12',\n",
       " './omniglot_resized/Glagolitic/character21']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metatest_character_folders[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Balinese',\n",
       "  'Mkhedruli_(Georgian)',\n",
       "  'Grantha',\n",
       "  'Atemayar_Qelisayer',\n",
       "  'Armenian'],\n",
       " ['./omniglot_resized/Balinese/character13/0120_10.png',\n",
       "  './omniglot_resized/Mkhedruli_(Georgian)/character41/0769_13.png',\n",
       "  './omniglot_resized/Grantha/character32/0382_03.png',\n",
       "  './omniglot_resized/Atemayar_Qelisayer/character16/1000_16.png',\n",
       "  './omniglot_resized/Armenian/character11/0037_04.png'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample_batch('train', batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N_Ko', './omniglot_resized/N_Ko/character12/0815_11.png'),\n",
       " ('Glagolitic', './omniglot_resized/Glagolitic/character21/1135_16.png'),\n",
       " ('asd', './omniglot_resized/Braille/character12/0203_15.png')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_images(data.metatest_character_folders[0:3],['asd','N_Ko','Glagolitic'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Braille', 'N_Ko', 'Glagolitic']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.basename(os.path.split(family)[0]) for family in data.metatest_character_folders[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
